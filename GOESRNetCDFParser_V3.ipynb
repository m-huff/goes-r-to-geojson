{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from pyproj import Proj, Transformer\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "INPUT_DIR = r\"E:\\GOES-R Lightning Data\\2023\"\n",
    "OUTPUT_CSV = r\"E:\\GOES-R Lightning Data\\Processed\\2023_flashes.csv\"\n",
    "MAX_WORKERS = 8\n",
    "BATCH_SIZE = 200  # Write every 200 processed flashes\n",
    "\n",
    "# ----------------------------\n",
    "# Worker Function\n",
    "# ----------------------------\n",
    "def process_file(file_path):\n",
    "    \"\"\"Extract the brightest flash location from one file.\"\"\"\n",
    "    try:\n",
    "        with Dataset(file_path, \"r\") as ds:\n",
    "            slot = getattr(ds, \"orbital_slot\", \"\").strip().lower()\n",
    "            if \"east\" in slot:\n",
    "                return None\n",
    "            elif \"west\" not in slot:\n",
    "                return None\n",
    "\n",
    "            proj_info = ds.variables[\"goes_imager_projection\"]\n",
    "            lon_origin = proj_info.longitude_of_projection_origin\n",
    "            H = proj_info.perspective_point_height + proj_info.semi_major_axis\n",
    "            r_eq = proj_info.semi_major_axis\n",
    "            r_pol = proj_info.semi_minor_axis\n",
    "\n",
    "            x = ds.variables[\"x\"][:]\n",
    "            y = ds.variables[\"y\"][:]\n",
    "\n",
    "            data = ds.variables[\"Total_Optical_energy\"][:].astype(float)\n",
    "            fill_value = getattr(ds.variables[\"Total_Optical_energy\"], \"_FillValue\", np.nan)\n",
    "            data[data == fill_value] = np.nan\n",
    "\n",
    "            if np.all(np.isnan(data)):\n",
    "                return None\n",
    "\n",
    "            iy, ix = np.unravel_index(np.nanargmax(data), data.shape)\n",
    "            max_value = data[iy, ix]\n",
    "            if np.isnan(max_value) or max_value <= 0:\n",
    "                return None\n",
    "\n",
    "            x_rad = x[ix]\n",
    "            y_rad = y[iy]\n",
    "\n",
    "            p = Proj(proj='geos', h=H, lon_0=lon_origin, a=r_eq, b=r_pol, units='m')\n",
    "            transformer = Transformer.from_proj(p, \"epsg:4326\", always_xy=True)\n",
    "\n",
    "            x_m = x_rad * H\n",
    "            y_m = y_rad * H\n",
    "\n",
    "            lon, lat = transformer.transform(x_m, y_m)\n",
    "\n",
    "            if not np.isfinite(lon) or not np.isfinite(lat):\n",
    "                return None\n",
    "\n",
    "            return {\n",
    "                \"file\": os.path.basename(file_path),\n",
    "                \"lon\": float(lon),\n",
    "                \"lat\": float(lat),\n",
    "                \"energy\": float(max_value)\n",
    "            }\n",
    "\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "def main():\n",
    "    files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(\".nc\")]\n",
    "    print(f\"Found {len(files)} NetCDF files\")\n",
    "\n",
    "    skipped = 0\n",
    "    batch = []\n",
    "\n",
    "    # Open CSV and write header\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"file\", \"lon\", \"lat\", \"energy\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            futures = {executor.submit(process_file, f): f for f in files}\n",
    "\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing files\"):\n",
    "                res = future.result()\n",
    "                if res:\n",
    "                    batch.append(res)\n",
    "                else:\n",
    "                    skipped += 1\n",
    "\n",
    "                # Write batch to CSV periodically\n",
    "                if len(batch) >= BATCH_SIZE:\n",
    "                    writer.writerows(batch)\n",
    "                    batch = []\n",
    "\n",
    "            # Write remaining rows\n",
    "            if batch:\n",
    "                writer.writerows(batch)\n",
    "\n",
    "    print(f\"Processed {len(files) - skipped} flashes\")\n",
    "    print(f\"Skipped {skipped} files\")\n",
    "    print(f\"Results saved to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
